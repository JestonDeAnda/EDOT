#!/usr/bin/env python
'''
EDOT_Adam_torch

PyTorch implementation of EDOT Adam optimizer.
Requires `torch` and `EDOT_disc_torch`.

Date: 2025.09.05

Python version >= 3.10
'''

import json
import os
from typing import Callable, List
from typing import Any, Dict, List, Optional, Tuple

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import torch

from . import EDOT_disc_torch
from .EDOT_disc_torch import gradient_EOT

# ç¡®ä¿ç»“æœç›®å½•å­˜åœ¨
os.makedirs("edot_results_adam_torch", exist_ok=True)


def EDOT_grad_wrapper(
    grad: Callable,
    subsample_sizes: int | List[int] | List[Callable] | None = None,
    zeta: float | list[float] | List[Callable] | None = None,
):
    """
    åŒ…è£…æ¢¯åº¦è®¡ç®—å‡½æ•°ï¼Œæ”¯æŒå­é‡‡æ ·å’Œæ­£åˆ™åŒ–ã€‚

    å‚æ•°:
        grad (Callable): åŸå§‹çš„æ¢¯åº¦è®¡ç®—å‡½æ•°ã€‚
        subsample_sizes (int | List[int] | List[Callable], å¯é€‰): å­é‡‡æ ·å¤§å°ã€‚
                    Callable[torch.Tensor] -> torch.Tensor | List, the mask
                    using which can generate the subsample tensor.
        zeta (float | list[float] | List[Callable], å¯é€‰): æ­£åˆ™åŒ–å‚æ•°ã€‚

    è¿”å›:
        Callable: åŒ…è£…åçš„æ¢¯åº¦è®¡ç®—å‡½æ•°ã€‚
    """
    count = 0
    # [TODO] see the other [TODO] below
    zeta = zeta[0] if isinstance(zeta, list) else zeta
    match subsample_sizes:
        case int() if subsample_sizes >= 2:
            mask_gen = lambda x: list(range(min(subsample_sizes, len(x))))

        # list case, å¯ä»¥æ˜¯intå’Œcallableçš„æ··åˆ
        case list() if len(subsample_sizes) > 0:
            count = min(len(subsample_sizes) - 1, count)
            if isinstance(subsample_sizes[count], int):
                mask_gen = lambda x: list(
                    range(min(max(subsample_sizes[count], 2), len(x))))
            elif isinstance(subsample_sizes[count], Callable):
                mask_gen = lambda x: subsample_sizes[count](x)

        case callable():
            mask_gen = lambda x: list(
                range(min(max(subsample_sizes[count], 2), len(x))))
        case _:
            mask_gen = lambda x: list(range(min(subsample_sizes, len(x))))

    def inner(sample, sample_weight, target, target_weight, **kwargs):
        nonlocal count, mask_gen, zeta
        print("Round:", count, f"zeta = {zeta:.5f}")
        _kwargs = {
            k: kwargs[k]
            for k in {"k", "exp", "distance", "distance_gradient"}  # "zeta"
            if k in kwargs
        }
        mask = mask_gen(sample)
        sample = sample[mask]
        ratio = sample_weight.sum() / torch.clamp(sample_weight[mask].sum(),
                                                  min=1e-10)
        sample_weight = sample_weight[mask] * ratio
        # [TODO] è¿™é‡Œçš„zetaç”¨ä¸€ä¸ªæ›´å¥½çš„æœºåˆ¶æ¥ä»£æ›¿
        while True:
            try:
                Dnu, Dy, cost = grad(sample,
                                     sample_weight,
                                     target,
                                     target_weight,
                                     zeta=zeta,
                                     **_kwargs)
            except Exception as e:
                # print(e)
                zeta *= 1.2
                continue
            if not torch.isnan(cost):
                zeta *= 0.8
                break
            zeta *= 1.2

        count += 1
        return Dnu, Dy, cost

    return inner


class EDOT_Torch:

    def __init__(self):
        pass
        self._grad = gradient_EOT
        self.grad = gradient_EOT

    def wrap_grad(self,
                  grad,
                  subsample_sizes,
                  zeta,
                  wrapper=EDOT_grad_wrapper):
        print("Grad Wrapped!")
        self.grad = wrapper(grad, subsample_sizes, zeta)

    def adam_discretize(
        self,
        disc: torch.Tensor,
        positions: torch.Tensor,
        weights: torch.Tensor,
        repeats: int = 5000,
        alpha: float = 0.005,
        beta1: float = 0.9,
        beta2: float = 0.999,
        epsilon: float = 1e-8,
        zeta: float = 0.004,
        use_pytorch_adam: bool = True
    ) -> Tuple[torch.Tensor, torch.Tensor, float, float]:
        """
        ä½¿ç”¨Adamä¼˜åŒ–å™¨ç¦»æ•£åŒ–EDOTæ¨¡å‹
        
        Parameters
        ----------
        disc: torch.Tensor, åˆå§‹ç¦»æ•£ç‚¹åæ ‡ï¼Œå½¢çŠ¶ä¸º(discrete_size, 2)
        positions: torch.Tensor, æ ·æœ¬ç‚¹åæ ‡ï¼Œå½¢çŠ¶ä¸º(sample_size, 2)
        weights: torch.Tensor, æ ·æœ¬ç‚¹æƒé‡ï¼Œå½¢çŠ¶ä¸º(sample_size)
        repeats: int, æœ€å¤§è¿­ä»£æ¬¡æ•°
        alpha: float, å­¦ä¹ ç‡
        beta1: float, ä¸€é˜¶çŸ©ä¼°è®¡çš„æŒ‡æ•°è¡°å‡ç‡
        beta2: float, äºŒé˜¶çŸ©ä¼°è®¡çš„æŒ‡æ•°è¡°å‡ç‡
        epsilon: float, æ•°å€¼ç¨³å®šæ€§å¸¸æ•°
        zeta: float, EOTæ­£åˆ™åŒ–å‚æ•°
        use_pytorch_adam: bool, æ˜¯å¦ä½¿ç”¨PyTorchè‡ªå¸¦çš„Adamä¼˜åŒ–å™¨
        
        Returns
        -------
        X: torch.Tensor, ä¼˜åŒ–åçš„ç¦»æ•£ç‚¹åæ ‡
        W: torch.Tensor, ä¼˜åŒ–åçš„ç¦»æ•£ç‚¹æƒé‡
        loss: float, æœ€ç»ˆæŸå¤±å€¼
        L: float, æœ€ç»ˆæ¢¯åº¦èŒƒæ•°
        """
        print(
            f"adam_discretize repeats={repeats}, use_pytorch_adam={use_pytorch_adam}"
        )

        # ç¡®ä¿è¾“å…¥æ˜¯PyTorchå¼ é‡å¹¶åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        X = disc.clone().to(device)
        positions = positions.to(device)
        weights = weights.to(device)

        # åˆå§‹åŒ–ç›®æ ‡ç‚¹æƒé‡
        W = torch.ones(X.shape[0], device=device) / X.shape[0]

        if use_pytorch_adam:
            # ä½¿ç”¨PyTorchè‡ªå¸¦çš„Adamä¼˜åŒ–å™¨
            # å°†Xå’ŒWè®¾ç½®ä¸ºéœ€è¦æ¢¯åº¦çš„å‚æ•°
            X.requires_grad_(True)
            W.requires_grad_(True)

            # åˆ›å»ºä¼˜åŒ–å™¨
            optimizer = torch.optim.Adam([X, W],
                                         lr=alpha,
                                         betas=(beta1, beta2),
                                         eps=epsilon)
            eps = 1e-5
            for i in range(repeats):
                # æ¸…é™¤ä¹‹å‰çš„æ¢¯åº¦
                optimizer.zero_grad()

                # è®¡ç®—æ¢¯åº¦å’ŒæŸå¤±
                grad_W, grad_X, loss = self.grad(positions,
                                                 weights,
                                                 X,
                                                 W,
                                                 zeta=zeta)

                # æ‰‹åŠ¨è®¾ç½®æ¢¯åº¦
                if X.grad is None:
                    X.grad = torch.zeros_like(X)
                if W.grad is None:
                    W.grad = torch.zeros_like(W)

                X.grad.data = grad_X
                W.grad.data = grad_W

                # æ‰§è¡Œä¼˜åŒ–æ­¥éª¤
                optimizer.step()

                # é™åˆ¶Xåæ ‡åœ¨å½’ä¸€åŒ–èŒƒå›´[0, 1]
                with torch.no_grad():
                    X.data = torch.clamp(X.data, 0.0, 1.0)

                    # ä¿æŒWæ˜¯ä¸€ä¸ªåˆæ³•çš„æ¦‚ç‡åˆ†å¸ƒ
                    W.data = torch.clamp(W.data, 1e-6, 1.0)
                    W.data = W.data / torch.sum(W.data)

                if i % 50 == 0 or i == repeats - 1:
                    with torch.no_grad():
                        L = torch.norm(grad_X) + torch.norm(grad_W)
                        print(
                            f"è¿­ä»£ {i}, Loss: {loss.item():.6f}, Grad Norm: {L.item():.6f}"
                        )
                        if L < eps:
                            print("å·²æ”¶æ•›")
                            break
        else:
            # æ‰‹åŠ¨å®ç°Adamä¼˜åŒ–
            z_X = 0
            z_W = 0
            m_X = torch.zeros_like(X)  # ä¸€é˜¶çŸ©ä¼°è®¡
            v_X = torch.zeros_like(X)  # äºŒé˜¶çŸ©ä¼°è®¡
            m_W = torch.zeros_like(W)  # ä¸€é˜¶çŸ©ä¼°è®¡
            v_W = torch.zeros_like(W)  # äºŒé˜¶çŸ©ä¼°è®¡
            eps = 1e-5

            for i in range(repeats):
                # è®¡ç®—æ¢¯åº¦å’ŒæŸå¤±
                grad_W, grad_X, loss = self.grad(positions,
                                                 weights,
                                                 X,
                                                 W,
                                                 zeta=zeta)

                # æ›´æ–°ä¸€é˜¶çŸ©å’ŒäºŒé˜¶çŸ©ä¼°è®¡
                m_X = beta1 * m_X + (1 - beta1) * grad_X
                v_X = beta2 * v_X + (1 - beta2) * (grad_X**2)

                m_W = beta1 * m_W + (1 - beta1) * grad_W
                v_W = beta2 * v_W + (1 - beta2) * (grad_W**2)

                # åå·®ä¿®æ­£
                m_X_hat = m_X / (1 - beta1**(i + 1))
                v_X_hat = v_X / (1 - beta2**(i + 1))

                m_W_hat = m_W / (1 - beta1**(i + 1))
                v_W_hat = v_W / (1 - beta2**(i + 1))

                # ä½¿ç”¨ Adam æ›´æ–°è§„åˆ™æ›´æ–°å‚æ•°
                X -= alpha * m_X_hat / (torch.sqrt(v_X_hat) + epsilon)
                W -= alpha * m_W_hat / (torch.sqrt(v_W_hat) + epsilon)

                # é™åˆ¶ X åæ ‡åœ¨å½’ä¸€åŒ–èŒƒå›´ [0, 1]ï¼Œé¿å…åå½’ä¸€åŒ–åè¶Šç•Œ
                X = torch.clamp(X, 0.0, 1.0)

                # ä¿æŒ W æ˜¯ä¸€ä¸ªåˆæ³•çš„æ¦‚ç‡åˆ†å¸ƒ
                W = torch.clamp(W, 1e-6, 1.0)
                W /= torch.sum(W)

                if i % 50 == 0 or i == repeats - 1:
                    L = torch.norm(grad_X) + torch.norm(grad_W)
                    print(
                        f"è¿­ä»£ {i}, Loss: {loss.item():.6f}, Grad Norm: {L.item():.6f}"
                    )
                    if L < eps:
                        print("å·²æ”¶æ•›")
                        break

        # ç¡®ä¿è¿”å›çš„æ˜¯CPUå¼ é‡ï¼Œä¾¿äºåç»­å¤„ç†
        return X.detach().cpu(), W.detach().cpu(), loss.item(), L.item()

    def discretize_from_coordinates(
            self,
            coord_points: np.ndarray,
            disc: Optional[np.ndarray] = None,
            weights: Optional[np.ndarray] = None,
            discrete_size: int = 4,
            repeats: int = 5000,
            use_pytorch_adam: bool = True,
            **args) -> Tuple[np.ndarray, np.ndarray, np.ndarray, float, float]:
        """
        ä»åæ ‡ç‚¹ç¦»æ•£åŒ–EDOTæ¨¡å‹
                Parameters
        ----------
        coord_points: np.ndarray, åæ ‡ç‚¹ï¼Œå½¢çŠ¶ä¸º(n, 2)
        disc: Optional[np.ndarray], åˆå§‹ç¦»æ•£ç‚¹åæ ‡ï¼Œå½¢çŠ¶ä¸º(discrete_size, 2)
        weights: Optional[np.ndarray], åˆå§‹ç¦»æ•£ç‚¹æƒé‡ï¼Œå½¢çŠ¶ä¸º(discrete_size)
        discrete_size: int, ç¦»æ•£ç‚¹æ•°é‡
        repeats: int, æœ€å¤§è¿­ä»£æ¬¡æ•°
        use_pytorch_adam: bool, æ˜¯å¦ä½¿ç”¨PyTorchè‡ªå¸¦çš„Adamä¼˜åŒ–å™¨
        **args: å…¶ä»–å‚æ•°ä¼ é€’ç»™adam_discretize
        
        Returns
        -------
        disc_rescaled: np.ndarray, ä¼˜åŒ–åçš„ç¦»æ•£ç‚¹åæ ‡ï¼ˆåå½’ä¸€åŒ–åï¼‰
        weights: np.ndarray, ä¼˜åŒ–åçš„ç¦»æ•£ç‚¹æƒé‡
        labels: np.ndarray, æ¯ä¸ªåæ ‡ç‚¹å¯¹åº”çš„ç¦»æ•£ç‚¹æ ‡ç­¾
        lastloss: float, æœ€ç»ˆæŸå¤±å€¼
        lastL: float, æœ€ç»ˆæ¢¯åº¦èŒƒæ•°
        """
        print(
            f"discretize_from_coordinates calls adam_discretize with repeats={repeats}"
        )
        print(f"discretize_size={discrete_size}")

        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        coord_points = np.asarray(coord_points, dtype=float)

        # å½’ä¸€åŒ–åæ ‡
        min_vals = coord_points.min(axis=0)
        max_vals = coord_points.max(axis=0)
        norm_coords = (coord_points - min_vals) / (max_vals - min_vals)

        # è½¬æ¢ä¸ºPyTorchå¼ é‡
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        norm_coords_torch = torch.tensor(norm_coords,
                                         dtype=torch.float32,
                                         device=device)
        wts = torch.ones(len(norm_coords), device=device) / len(norm_coords)

        # åˆå§‹åŒ–ç¦»æ•£ç‚¹
        if disc is None:
            disc_torch = torch.rand(discrete_size, 2,
                                    device=device) * 0.9 + 0.05
            disc_torch += torch.rand(discrete_size, 2, device=device) * 1e-1
        else:
            disc_torch = torch.tensor(disc, dtype=torch.float32, device=device)

        if weights is None:
            weights_torch = torch.ones(discrete_size,
                                       device=device) / discrete_size
        else:
            weights_torch = torch.tensor(weights,
                                         dtype=torch.float32,
                                         device=device)

        # è°ƒç”¨Adamä¼˜åŒ–
        disc_torch, weights_torch, lastloss, lastL = self.adam_discretize(
            disc_torch,
            norm_coords_torch,
            wts,
            repeats=repeats,
            use_pytorch_adam=use_pytorch_adam,
            **args)

        # åå½’ä¸€åŒ–
        disc_rescaled = disc_torch.numpy() * (max_vals - min_vals) + min_vals

        # è®¡ç®—æ ‡ç­¾
        distances = np.zeros((len(coord_points), discrete_size))
        for i in range(len(coord_points)):
            for j in range(discrete_size):
                distances[i, j] = np.sum(
                    (coord_points[i] - disc_rescaled[j])**2)
        labels = np.argmin(distances, axis=1)

        return disc_rescaled, weights_torch.numpy(), labels, lastloss, lastL


def main():
    # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯é‡å¤
    torch.manual_seed(42)
    np.random.seed(42)

    sheetnames = ['12-1']
    for sheet in sheetnames:
        print(f"Processing sheet: {sheet}")

        df = pd.read_excel("E:/behavioral data/eyetracking_faceid.xlsx",
                           sheet_name=sheet)
        trialcol = df['trial'].values
        trials = np.unique(trialcol)

        for tri in trials[6:9]:
            print(f"Processing trial {tri}")
            df_trial = df[df['trial'] == tri]
            if len(df_trial) < 10:
                print(f"Skipping trial {tri} due to insufficient data")
                continue

            x = df_trial['x_position'].values
            y = df_trial['y_position'].values
            eye_movements = np.column_stack((x, y))

            edot_model = EDOT_Torch()
            discrete_sizes = range(3, 4)

            for size in discrete_sizes:
                print(f"\n=== å¤„ç† discrete_size = {size} ===")

                # ä½¿ç”¨PyTorch Adamä¼˜åŒ–å™¨
                centers, weights, labels, lastloss, lastL = edot_model.discretize_from_coordinates(
                    eye_movements,
                    discrete_size=size,
                    repeats=5000,
                    use_pytorch_adam=True)

                # å‡†å¤‡ç»“æœå­—å…¸
                trial_result = {
                    size: {
                        "centers": centers.tolist(),
                        "weights": weights.tolist(),
                        "loss": float(lastloss),
                        "final_gradient": float(lastL)
                    }
                }

                # ä¿å­˜ JSON æ–‡ä»¶ï¼ˆæ¯ä¸ª trial å•ç‹¬ä¿å­˜ï¼‰
                json_path = f"edot_results_adam_torch/{sheet}_edot_summary_trial_{int(tri)}_size_{int(size)}.json"
                with open(json_path, "w", encoding="utf-8") as f:
                    json.dump(trial_result, f, ensure_ascii=False, indent=2)

                print(f"âœ… Trial {tri} çš„ç»“æœå·²ä¿å­˜ä¸º {json_path}")

                # å¯è§†åŒ–
                colors = plt.cm.get_cmap('tab20', size)(
                    labels % 20)  # é˜²æ­¢æ ‡ç­¾æ•°è¶…è¿‡ colormap èŒƒå›´

                plt.figure(figsize=(19.2, 10.8), dpi=100)
                image_path = "E:/behavioral data/image/task_see/EF_gt_185.png"
                if os.path.exists(image_path):
                    img = plt.imread(image_path)
                    plt.imshow(img, extent=[0, 1920, 1080, 0])
                else:
                    print(f"âš ï¸ å›¾åƒæ–‡ä»¶æœªæ‰¾åˆ°: {image_path}, ä½¿ç”¨ç©ºèƒŒæ™¯")

                plt.scatter(x,
                            y,
                            c=colors,
                            alpha=0.7,
                            label='eyemovements',
                            zorder=1)

                # æ ¹æ®æƒé‡è®¾ç½®ä¸­å¿ƒç‚¹å¤§å°
                plt.scatter(centers[:, 0],
                            centers[:, 1],
                            c='red',
                            s=weights * 2000,
                            marker='X',
                            label='centers',
                            zorder=2)

                for i, center in enumerate(centers):
                    plt.text(center[0],
                             center[1],
                             f'{i+1}',
                             fontsize=12,
                             ha='center',
                             va='center',
                             bbox=dict(facecolor='white',
                                       alpha=0.8,
                                       edgecolor='none'),
                             zorder=3)

                plt.title(
                    f"EDOT result (regions={size}), Trial {tri}, lastL={lastL:.5f}"
                )
                plt.xlabel("X (pixels)")
                plt.ylabel("Y (pixels)")
                plt.xlim(0, 1920)
                plt.ylim(1080, 0)
                plt.legend()
                plt.grid(False)

                img_save_path = f"edot_results_adam_torch/{sheet}_trial{tri}_clustering_size_{size}.png"
                plt.savefig(img_save_path, dpi=300, bbox_inches='tight')
                plt.close()

                print(f"ğŸ–¼ï¸ Trial {tri} çš„èšç±»å›¾å·²ä¿å­˜ä¸º {img_save_path}")


if __name__ == "__main__":
    main()

__all__ = ['EDOT_Torch']
